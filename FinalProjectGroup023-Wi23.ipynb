{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Final Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Uniqlo Stock Prices using Random Forest Algorithm\n",
    "\n",
    "## Group members\n",
    "\n",
    "- Brian Chen\n",
    "- Jeffrey Chen\n",
    "- Vivian Cheung\n",
    "- Zhangxiang Lu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "In this project, our goal is to predict Uniqlo closing stock prices from a dataset we procured from Kaggle. Each data point in our dataset contains Uniqlo opening, high, low, and closing stock prices as well as volume of stocks traded and trading values from Jan 2012 - Dec 2016. This data was taken from the Japanese stock market. With our data we will be using a random forest model along with k-fold cross validation to predict closing stock prices per day. To evaluate the success of our model we will compare our predictions to the actual Uniqlo closing stock price. Our model's performance will be evaluated on statistical metrics such as root mean square error, mean absolute error, and mean squared error.\n",
    "\n",
    "__NB:__ this final project form is much more report-like than the proposal and the checkpoint. Think in terms of writing a paper with bits of code in the middle to make the plots/tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Predicting stock prices has been a popular research area in the field of machine learning and finance for a long time. Various studies have been conducted to predict stock prices using different algorithms and techniques. The majority of these studies have focused on analyzing historical stock price data, company financial reports, and other macroeconomic indicators to make predictions about future stock prices.\n",
    "\n",
    "One popular approach to stock price prediction is time series analysis. Time series analysis involves using past prices and other relevant variables to forecast future prices. There are many different models that can be used for time series analysis, including autoregressive integrated moving average (ARIMA) models, autoregressive conditional heteroscedasticity (ARCH) models, and recurrent neural networks (RNNs) <a name=\"Tsay\"></a>[<sup>[1]</sup>](#Tsay) <a name=\"Engle\"></a>[<sup>[2]</sup>](#Engle) <a name=\"Hochreiter\"></a>[<sup>[3]</sup>](#Hochreiter).\n",
    "\n",
    "Another popular approach to stock price prediction is machine learning. Machine learning algorithms can be trained to learn patterns in historical data and use those patterns to make predictions about future prices. Popular machine learning algorithms for stock price prediction include support vector machines (SVMs), random forests, and gradient boosting machines (GBMs) <a name=\"Zhang\"></a>[<sup>[4]</sup>](#Zhang) <a name=\"Zhang2\"></a>[<sup>[5]</sup>](#Zhang2).\n",
    "\n",
    "In recent years, deep learning techniques such as convolutional neural networks (CNNs) and long short-term memory (LSTM) networks have been applied to stock price prediction with promising results. These techniques can capture complex patterns in historical data and make accurate predictions about future prices <a name=\"Zhang3\"></a>[<sup>[6]</sup>](#Zhang3) <a name=\"Qiu\"></a>[<sup>[7]</sup>](#Qiu)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Originally in this project we aimed to use a Random Forest Algorithm to predict the daily closing values of Uniqlo's stock from January 2012 - December 2016. When delving into the problem of implementing the model, however, it ended up being more prudent to predict stock price movement through a different, industry-relevant metric: *the five-day percent change in the stock closing price*. This metric provides a better idea of overall stock price movement for any potential investors and is less subject to day-to-day volatility. To accomplish this, we will analyze factors such as opening stock price, daily highs and lows, trading volume, and trading value of Uniqlo stock. We will also create new features for our data set based off the commonly used Moving Average and Relative Strength Index indicators for stock trading. \n",
    "\n",
    "Since our data is procured from the Tokyo Stock Exchange, we will be quantifying stock prices in terms of Japanese Yen (¥) to match our dataset. Furthermore, our problem is measureable because we can calculate our model's accuracy by taking the difference between our model's predicted closing stock prices and the actual closing stock prices and measure error with metrics such as Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), or Mean Squared Error (MSE). Finally, our problem is replicable because a machine learning model can be used to predict more recent Uniqlo closing stock prices such as from 2017 to 2023."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Link to our dataset: https://www.kaggle.com/datasets/daiearth22/uniqlo-fastretailing-stock-price-prediction\n",
    "\n",
    "Our dataset contains 1227 observations organized by date and 7 variables. Each observation consists of a date, opening price, high, low, closing price, volume, and stock trading value. We consider \"opening price\", \"high\", \"low\", \"closing price\", \"volume\", and \"stock trading\" to be critical variables. Every variable is represented by an integer value and every variable except volume is in terms of Japanese Yen ¥. \n",
    "\n",
    "### Data Cleaning and Transformations\n",
    "\n",
    "In terms of cleaning and transformations for our data, we did not have to do much. We planned on using all the variables included within the training dataset, with only minor modifications. We had originally planned to set the \"date\" values as the indices for our new dataset but these plans were stymied by the discontinuity of date values. Given stock market regulations, trading does not occur on weekends or holidays, leaving irregular holes in our date values. Thus, we stuck to using numerical indices from 1 through 1226.\n",
    "\n",
    "Both the training and test datasets were also in reverse-chronological order, meaning one of our first steps was reversing the datasets and validating the new datasets were in the correct order. Furthermore, we changed the \"stock trading\" column into a \"trading value\" column to better convey the actual significance of the variable's values. \n",
    "\n",
    "As part of our feature engineering, which we cover down below, we created multiple moving-average variables, the longest of which spans 200 days. In order to appropriately calculate and utilize this metric, we applied the calculation to the whole dataset and then dropped the first 200 data points from the actual training set. This is because for those first 200 data points, there was not sufficient data before those dates to calculate a 200-day moving average, and they would have introduced null-values that the model was not prepared to handle. The remaining 1027 data points will be used in a chronological 85/15 train/test split.\n",
    "\n",
    "### Updating Prediction Variable\n",
    "\n",
    "After conducting research, we learned about the five-day percent change as an industry-relevant metric for predicting stock price movement, which we chose to predict as opposed to closing prices.\n",
    "\n",
    "### Feature Engineering\n",
    "\n",
    "After creating a preliminary random forest regression model and fitting it to our training dataset to predict closing prices, we found that its performance in terms of MSE was significantly worse than that of our benchmark linear regression model. We then feature engineered more predictor variables, namely moving averages (MA), relative strength indices (RSI), and daily volume changes. Using the talib library and dataframe methods, we created moving average and relative strength index features for spans of 14, 30, 50, and 200 days. This allowed us to get better performance out of our random forest regression model and a better MSE than our benchmark linear regression model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared.\n",
    "\n",
    "Using our Uniqlo dataset, we want to predict its closing stock price, while measuring performance. To do so, our project will utilize the Random Forest algorithm, which we believe will work based on the past success of others who have it used for stock prediction. We will run the model using various combinations of the possible features (\"opening price\", \"high\", \"low\", \"closing price\", \"volume\", and \"stock trading\") in order to determine which features result in the best performance. High performing features will result in the lowest MSE between actual and predicted closing prices. We will use K-Fold cross validation since our sample size is low (1227) to assess our model's performance and make the most of our small dataset. Some libraries that we plan to use are NumPy, SKlearn, and Matplotlib. We plan to use linear regression as a benchmark model to compare our random forest model's performance against."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "When evaluating the success of our model, we will compare the predictions to the actual Uniqlo stock prices. For our evaluation metrics, we plan to use statistical metrics such as root mean square error, mean absolute error, and mean squared error for calculating risks and evaluating the prediction accuracy. \n",
    "\n",
    "Mean absolute error is the absolute difference between the predicted and actual values, which can help with evaluating the size of the error. MAE is calculated by $MAE=(1/n)*\\sum |y_i-\\hat{y}_i|$\n",
    "\n",
    "Mean squared error is the average of the squared differences between the predicted and actual values. This essentially plays a similar role to MAE, but gives more weight to larger errors. This lends itself useful in the context of our project if we want to evaluate our errors with significantly incorrect stock value predictions. The equation for MSE is $MSE=(1/n)*\\sum(y_i-\\hat{y}_i)^2$\n",
    "\n",
    "Finally, the last of the statistical metrics we'll use is root mean squared error, which essentially takes the square root of the MSE and similarly penalizes larger errors more than smaller errors, just in a more readable way. It's calculated by $RMSE=\\sqrt{(1/n)*\\sum(y_i-\\hat{y}_i)^2}$\n",
    "\n",
    "The reason why we selected MSE and RMSE in particular is due in part to the fact that stock predictions carry a lot of weight in that they can cause people to potentially gain or lose a significant amount of money. Therefore, these two evaluation metrics in particular will call attention to poor prediction models that have large errors. Therefore, we can minimize the risk of significantly penalizing those who use this model as financial advice. \n",
    "\n",
    "Overall, the goal is to ensure that it is accurately predicting the direction of the stock and the amount it increases/decreases by. As our dataset has already been separated into training and testing data, we will use the cleaned dataset to evaluate the success of our prediction model and its accuracy using these statistical metrics."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Baseline Linear Regression\n",
    "\n",
    "During our data exploration process, we discovered that the closing prices of Uniqlo from 2012-2016 were fairly linear with few significant dips in stock prices. Therefore, when selecting our base model, we decided that a Linear Regression Model would be fitting to use with our dataset and should be a good indicator of the hyperparameters to be used with our future model. Surprisingly, we found that even the base model performed fairly well, with a mean squared error of JP¥75490.9417 ($574.47 USD). Still, we wanted to try to optimize our prediction algorithm further using other models utilized in stock prediction. As our problem statement aims to forecast stock prices based on the provided Uniqlo historical stock data, we decided on random forest due to its noted success with predicting stock values.\n",
    "\n",
    "### Random Forest w/ Grid Search\n",
    "We decided to run Random Forest with Grid Search on our dataset. Surprisingly, this resulted in an even worse mean squared error of JP¥158637.1531 ($1208.66 USD), more than 2 times worse than our baseline linear regression. We attempted to standardize the data to see if it would improve our MSE, but our new MSE was basically the same, JP¥153671.9183 ($1170.83 USD). These were not the results we were expecting at all, so we attempted some feature engineering.\n",
    "\n",
    "### Feature Engineering\n",
    "\n",
    "After evaluating the performance of our random forest regression model with gridsearch and seeing that it was worse than our benchmark linear regression model, we wanted to make changes to our model to increase its performance. Part of this process involved feature engineering, in which we created new features using features from our original dataset. The new features we engineered were moving average (MA), relative strength index (RSI), and daily volume change. From research, we found that these predictors are heavily involved in machine learning techniques for predicting stock prices. We constructed MA and RSI variables for spans of 14, 30, 50, and 200 days. After executing our new random forest regression model with these added features, not only did we see better performance out of our model than our benchmark linear regression model, but we also found that our 14-day moving average feature that was constructed was the most important feature in predicting 5-day close price change percent.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "In terms of ethics and privacy concerns, we do not consider our project to have serious ethical implications. Theoretically, if our model were to be perfectly accurate or highly accurate in predicting Uniqlo stock prices, one could use our model in their financial interest. On the flip side, if our model were incredibly bad and it were to be publicized as a great model, it could cause people to lose a lot of money if they were to adhere to our model. As a result, it is important to clarify that our project is not financial advice and should not be used to inform any personal financial decisions.\n",
    "\n",
    "Another concern is the potential impact on market behavior. If the model is used to make significant financial decisions, it could potentially impact the stock prices and create a feedback loop where the model's predictions influence the market behavior, which in turn affects the stock prices. This could create unintended consequences and potential ethical issues that need to be considered.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Overall, Random Forest is not a very good model to deploy when actually using real money to trade stocks. Random Forest performed just slightly better than our baseline linear regression model after some , although linear regression likely just performed well on our particular dataset due to the Uniqlo stock price movement being approximately linear in shape by chance in the time frame that we were looking at. In addition, we noticed significant overfitting in our model, which means any future predictions made with this model will probably not be trustworthy enough to bet real money on. Actual models that have been successfully deployed in real stock trading by companies like Citadel or BlackRock are much more complex and gatekept from the public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"Tsay\"></a>1.[^](#Tsay): Tsay, R. S. (2018). Analysis of Financial Time Series (3rd ed.). *Wiley.*<br> \n",
    "<a name=\"Engle\"></a>2.[^](#Engle): Engle, R. F. (2001). GARCH 101: The Use of ARCH/GARCH Models in Applied Econometrics. *Journal of Economic Perspectives, *15(4), 157-168.<br>\n",
    "<a name=\"Hochreiter\"></a>3.[^](#Hochreiter): Hochreiter, S., & Schmidhuber, J. (1997). Long Short-Term Memory. *Neural Computation*, 9(8), 1735-1780.<br>\n",
    "<a name=\"Zhang\"></a>4.[^](#Zhang): Zhang, G., & Qi, Y. (2005). Neural Networks for Technical Analysis: A Study on KLCI. *International Journal of Intelligent Systems in Accounting, Finance and Management*, 13(1), 1-11.<br> \n",
    "<a name=\"Zhang2\"></a>5.[^](#Zhang2): Zhang, G., Patuwo, B. E., & Hu, M. Y. (1998). Forecasting with Artificial Neural Networks: The State of the Art. *International Journal of Forecasting*, 14(1), 35-62.<br>\n",
    "<a name=\"Zhang3\"></a>6.[^](#Zhang3): Zhang, Y., Liu, Y., & Li, Y. (2019). Stock Price Prediction Using Convolutional Neural Network. IEEE Access, 7, 112505-112514.<br>\n",
    "<a name=\"Qiu\"></a>7.[^](#Qiu): Qiu, Z., Chen, X., Wu, Y., & Yang, Y. (2019). A Novel Hybrid Model for Stock Price Prediction Based on LSTM and GRU. IEEE Access, 7, 96655-96663.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
